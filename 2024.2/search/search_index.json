{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#teachers","title":"Teachers","text":"<ul> <li>Geert van Geest  </li> </ul>"},{"location":"#authors","title":"Authors","text":"<ul> <li>Geert van Geest  </li> <li>Patricia Palagi  </li> </ul>"},{"location":"#license-copyright","title":"License &amp; copyright","text":"<p>License: CC BY 4.0</p> <p>Copyright: SIB Swiss Institute of Bioinformatics</p>"},{"location":"#learning-outcomes","title":"Learning outcomes","text":"<p>After this course, you will be able to:</p> <ul> <li>Understand important aspects of NGS and read alignment for variant analysis</li> <li>Perform a read alignment ready for variant analysis</li> <li>Perform variant calling according to GATK best practices</li> <li>Perform a variant annotation</li> </ul>"},{"location":"#learning-experiences","title":"Learning experiences","text":"<p>This course will consist of lectures, exercises and polls. During exercises, you are free to discuss with other participants. During lectures, focus on the lecture only.</p>"},{"location":"course_schedule/","title":"Course schedule","text":"<p>Note</p> <p>Apart from the starting time the time schedule is indicative. Because we can not plan a course by the minute, in practice the time points will deviate. </p>"},{"location":"course_schedule/#day-1","title":"Day 1","text":"block start end subject block 1 9:15 AM 10:30 AM Introduction 10:30 AM 11:00 AM BREAK block 2 11:00 AM 12:30 PM Setup &amp; Reproducibility 12:30 PM 1:30 PM BREAK block 3 1:30 PM 3:00 PM Read alignment - basics 3:00 PM 3:30 PM BREAK block 4 3:30 PM 5:00 PM Read alignment - advanced"},{"location":"course_schedule/#day-2","title":"Day 2","text":"block start end subject block 1 9:15 AM 10:30 AM Variant calling - preparation 10:30 AM 11:00 AM BREAK block 2 11:00 AM 12:30 PM Variant calling 12:30 PM 1:30 PM BREAK block 3 1:30 PM 3:00 PM Filtering &amp; evaluation &amp; Visualisation 3:00 PM 3:30 PM BREAK block 4 3:30 PM 5:00 PM Annotation"},{"location":"precourse/","title":"Precourse preparations","text":""},{"location":"precourse/#unix","title":"UNIX","text":"<p>As is stated in the course prerequisites at the announcement web page, we expect participants to have a basic understanding of working with the command line on UNIX-based systems. You can test your UNIX skills with a quiz here. If you don\u2019t have experience with UNIX command line, or if you\u2019re unsure whether you meet the prerequisites, follow our online UNIX tutorial.</p>"},{"location":"precourse/#software","title":"Software","text":"<p>We will be mainly working on an Amazon Web Services (AWS)  Elastic Cloud (EC2) server. Our Ubuntu server behaves like a \u2018normal\u2019 remote server, and can be approached through a VS code web interface. All participants will be granted access to a personal workspace to be used during the course.</p> <p>The only software you need to install before the course is Integrative Genomics Viewer (IGV).</p> <p>For self-learners</p> <p>Self learners can install the required software via conda, or run the VS code web interface inside a container. More instructions at Setup</p>"},{"location":"day1/alignment/","title":"Read alignment - basics","text":""},{"location":"day1/alignment/#learning-outcomes","title":"Learning outcomes","text":"<p>After having completed this chapter you will be able to:</p> <ul> <li>Describe the general workflow of library preparation and sequencing with an Illumina sequencer</li> <li>Explain how the fastq format stores sequence and base quality information</li> <li>Calculate probability from phred quality and the other way around</li> <li>Explain why base quality and mapping quality are important for detecting variants</li> <li>Illustrate the difference between short-read and long-read sequencing</li> <li>Explain which type of invention led to development of long-read sequencing</li> <li>Explain what impact long read sequencing can have on variant analysis</li> <li>Describe how alignment information is stored in a sequence alignment (<code>.sam</code>) file</li> <li>Define a duplicate alignment and explain how alignment duplicates can affect variant analysis</li> <li>Perform an alignment of genomic reads with <code>bwa mem</code></li> <li>Generate and interpret the alignment statistics from <code>samtools flagstat</code></li> </ul>"},{"location":"day1/alignment/#material","title":"Material","text":"<p> Download the presentation</p>"},{"location":"day1/alignment/#exercises","title":"Exercises","text":"<p>Running into problems during the exercises?</p> <p>Use the \u201cComments\u201d box at the bottom of each page \ud83d\udc47 for asking questions or giving feedback. It requires a github account.</p>"},{"location":"day1/alignment/#1-download-data-and-prepare-the-reference-genome","title":"1. Download data and prepare the reference genome","text":"<p>Let\u2019s start with the first script of our \u2018pipeline\u2019. We will use it to download and unpack the course data. Use the code snippet below to create a script called <code>A01_download_course_data.sh</code>. Store it in <code>~/project/scripts/A-prepare_references/</code>, and run it.</p> A01_download_course_data.sh<pre><code>#!/usr/bin/env bash\ncd ~/project\n\nwget https://ngs-variants-training.s3.eu-central-1.amazonaws.com/ngs-variants-training.tar.gz\ntar -xvf ngs-variants-training.tar.gz\nrm ngs-variants-training.tar.gz\n</code></pre> <p>Exercise: This will create the directory <code>data</code>. Check out what\u2019s in there.</p> Answer <p>The directory data contains the following: <pre><code>data\n\u251c\u2500\u2500 fastq\n\u2502   \u251c\u2500\u2500 father_R1.fastq.gz\n\u2502   \u251c\u2500\u2500 father_R2.fastq.gz\n\u2502   \u251c\u2500\u2500 mother_R1.fastq.gz\n\u2502   \u251c\u2500\u2500 mother_R2.fastq.gz\n\u2502   \u251c\u2500\u2500 son_R1.fastq.gz\n\u2502   \u2514\u2500\u2500 son_R2.fastq.gz\n\u251c\u2500\u2500 reference\n\u2502   \u2514\u2500\u2500 Homo_sapiens.GRCh38.dna.chromosome.20.fa\n\u2514\u2500\u2500 variants\n    \u251c\u2500\u2500 1000g_gold_standard.indels.filtered.vcf\n    \u251c\u2500\u2500 GCF.38.filtered.renamed.vcf\n    \u251c\u2500\u2500 NA12878.vcf.gz\n    \u2514\u2500\u2500 NA12878.vcf.gz.tbi\n\n3 directories, 11 files\n</code></pre></p> <p>These are:</p> <ul> <li>input reads (at <code>fastq</code>)</li> <li>a part of the human reference genome (at <code>reference</code>)</li> <li>some vcfs with variants for calibration and evaluation (at <code>variants</code>)</li> </ul> <p>Use <code>data</code> only for input</p> <p>The directory <code>data</code> that you have just downloaded, contains only input files for the exercises. So, don\u2019t write output (except for indexes) to this directory.</p> <p>In order to index the reference sequence we are going to need some bioinformatics tools. All required tools are pre-installed in a conda environment called <code>ngs-tools</code>. In order to use them, every time you open a new terminal, you will have to load the environment:</p> <pre><code>conda activate ngs-tools\n</code></pre> <p>activate ngs-tools</p> <p>Every time you open a new terminal you will have to activate the environment again.</p> <p>The software <code>bwa</code> is in this environment. We will use it for the alignment. Like all alignment software, it requires an index of the reference genome. You can make an index like this:</p> <pre><code>bwa index &lt;reference.fa&gt;\n</code></pre> <p>Make an index of the reference sequence of chromosome 20 of the human genome. You can find the fasta file in <code>~/project/data/reference/Homo_sapiens.GRCh38.dna.chromosome.20.fa</code>. Do it with a script called <code>A02_create_bwa_index.sh</code>. Also store this in the directory <code>A-prepare_references</code>.</p> Answer A02_create_bwa_index.sh<pre><code>#!/usr/bin/env bash\n\ncd ~/project/data/reference/\nbwa index Homo_sapiens.GRCh38.dna.chromosome.20.fa\n</code></pre>"},{"location":"day1/alignment/#2-read-alignment","title":"2. Read alignment","text":"<p>Check out the synopsis and manual of <code>bwa mem</code>. We\u2019ll be using paired-end reads of three samples that can be found at <code>~/project/data/fastq</code>. If we run <code>bwa mem</code> with default options, which three arguments do we need?</p> Answer <p>The manual says: <pre><code>bwa mem [-aCHMpP] [-t nThreads] [-k minSeedLen] ... db.prefix reads.fq [mates.fq]\n</code></pre> So, we\u2019ll need:</p> <ul> <li>a database prefix (<code>db.prefix</code>)</li> <li>forward reads (<code>reads.fq</code>)</li> <li>reverse reads (<code>mates.fq</code>)</li> </ul> <p>For our reference sequence a command would look like:</p> <pre><code>cd ~/project/\n\nbwa mem \\\ndata/reference/Homo_sapiens.GRCh38.dna.chromosome.20.fa \\\n&lt;forward_reads.fq&gt; \\\n&lt;reverse_reads.fq&gt; \\\n&gt; &lt;alignment.sam&gt;\n</code></pre> <p>We will now go through all the steps concerning alignment for the sample <code>mother</code>. To store the results of these steps, we will create a directory within <code>~/project</code> called <code>results</code>. For the alignment, make a script called <code>B01_alignment.sh</code>. Since we will perform a similar analysis later on for all samples, we store this script in<code>~/project/scripts/B-mother_only</code>. </p> <p>Your directory <code>~/project/scripts</code> should now like this:</p> <pre><code>scripts\n\u251c\u2500\u2500 A-prepare_references\n\u2502   \u251c\u2500\u2500 A01_download_course_data.sh\n\u2502   \u251c\u2500\u2500 A02_create_bwa_index.sh\n\u251c\u2500\u2500 B-mother_only\n\u2502   \u2514\u2500\u2500 B01_alignment.sh\n\u2514\u2500\u2500 C-all_samples\n</code></pre> <p>In <code>B01_alignment.sh</code> write the commands to perform an alignment with <code>bwa mem</code> of the reads from the mother (<code>mother_R1.fastq</code> and <code>mother_R2.fastq</code>) against chromosome 20. Write the resulting <code>.sam</code> file to a directory in <code>~/project/results</code> called <code>alignments</code>.</p> <p>Index prefix is the same a reference filename</p> <p>With default values, the name of the index of a reference for <code>bwa mem</code> is the same as the name of the reference itself. In this case, this would be <code>Homo_sapiens.GRCh38.dna.chromosome.20.fa</code>.</p> Answer B01_read_alignment.sh<pre><code>#!/usr/bin/env bash\n\ncd ~/project/\nmkdir -p results/alignments\n\nbwa mem \\\ndata/reference/Homo_sapiens.GRCh38.dna.chromosome.20.fa \\\ndata/fastq/mother_R1.fastq.gz \\\ndata/fastq/mother_R2.fastq.gz \\\n&gt; results/alignments/mother.sam\n</code></pre>"},{"location":"day1/alignment/#3-alignment-statistics","title":"3. Alignment statistics","text":"<p>Exercise: Check out the statistics of the alignment by using <code>samtools flagstat</code>. Write the output of samtools flagstat to a file called <code>mother.sam.flagstat</code>. Do this by creating a script called <code>B02_get_alignment_statistics.sh</code>, and add this script to <code>~/project/scripts/B-mother_only</code>. Find the documentation of <code>samtools flagstat</code> here. Any duplicates in there?</p> Answer B02_get_alignment_statistics.sh<pre><code>#!/usr/bin/env bash\n\ncd ~/project/results/alignments\nsamtools flagstat mother.sam &gt; mother.sam.flagstat\n</code></pre> <p>This should result in:</p> <pre><code>133477 + 0 in total (QC-passed reads + QC-failed reads)\n0 + 0 secondary\n317 + 0 supplementary\n0 + 0 duplicates\n132892 + 0 mapped (99.56% : N/A)\n133160 + 0 paired in sequencing\n66580 + 0 read1\n66580 + 0 read2\n131470 + 0 properly paired (98.73% : N/A)\n131990 + 0 with itself and mate mapped\n\n585 + 0 singletons (0.44% : N/A)\n0 + 0 with mate mapped to a different chr\n0 + 0 with mate mapped to a different chr (mapQ&gt;=5)\n</code></pre> <p>No duplicates were found (<code>0 + 0 duplicates</code>). The aligner doesn\u2019t automatically flag duplicates. This needs to be done after the alignment.</p>"},{"location":"day1/alignment/#4-sorting-and-compression","title":"4. Sorting and compression","text":"<p>Many downstream analyses require a coordinate sorted alignment file. Now, your alignment file is in the same order as the fastq file. You can coordinate sort an alignment file with <code>samtools sort</code>. You can find the documentation here. </p> <p>Exercise: Sort the alignment file according to coordinate. In order to do this, create a script called <code>B03_sort_alignment.sh</code> (in <code>~/project/scripts/B-mother_only</code>). </p> Answer B03_sort_alignment.sh<pre><code>#!/usr/bin/env bash\n\ncd ~/project/results\n\nsamtools sort -o alignments/mother.sorted.sam alignments/mother.sam \n</code></pre> <p>Tip: <code>samtools sort</code> and <code>samtools view</code> can write to stdout</p> <p>Like <code>bwa mem</code>, <code>samtools sort</code> and <code>samtools view</code> can write its output to stdout. This means that you need to redirect your output to a file with <code>&gt;</code> or use the the output option <code>-o</code>.</p> <p>The command <code>samtools view</code> is very versatile. It takes an alignment file and writes a filtered or processed alignment to the output. You can for example use it to compress your SAM file into a BAM file. Let\u2019s start with that.</p> <p>Exercise: compress our SAM file into a BAM file and include the header in the output. For this, use the <code>-b</code> and <code>-h</code> options. Perform the calculation from a script called <code>B04_compress_alignment.sh</code> (in <code>~/project/scripts/B-mother_only</code>).  Find the required documentation here. How much was the disk space reduced by compressing the file?</p> Answer <p>B04_compress_alignment.sh<pre><code>#!/usr/bin/env bash\n\ncd ~/project/results\n\nsamtools view -bh alignments/mother.sorted.sam &gt; alignments/mother.bam\n</code></pre> By using <code>ls -lh</code>, you can find out that <code>mother.sorted.sam</code> has a size of 55 Mb, while <code>mother.bam</code> is only 16 Mb.  </p>"},{"location":"day1/alignment/#5-recap","title":"5. Recap","text":"<p>You have now performed:</p> <ul> <li>alignment</li> <li>sorting </li> <li>compression</li> <li>flag statistics </li> </ul> <p>On the sample <code>mother</code>. Your scripts directory should look like this:</p> <pre><code>scripts\n\u251c\u2500\u2500 A-prepare_references\n\u2502   \u251c\u2500\u2500 A01_download_course_data.sh\n\u2502   \u2514\u2500\u2500 A02_create_bwa_index.sh\n\u251c\u2500\u2500 B-mother_only\n\u2502   \u251c\u2500\u2500 B01_alignment.sh\n\u2502   \u251c\u2500\u2500 B02_get_alignment_statistics.sh\n\u2502   \u251c\u2500\u2500 B03_sort_alignment.sh\n\u2502   \u2514\u2500\u2500 B04_compress_alignment.sh\n\u2514\u2500\u2500 C-all_samples\n</code></pre>"},{"location":"day1/alignment_advanced/","title":"Read alignment - advanced","text":""},{"location":"day1/alignment_advanced/#learning-outcomes","title":"Learning outcomes","text":"<p>After having completed this chapter you will be able to:</p> <ul> <li>Use <code>samtools</code> to mark duplicates from an alignment file</li> <li>Use <code>samtools</code> to add readgroups to an alignment file</li> <li>Use a for loop in bash to perform the same operation on a range of files</li> <li>Use <code>samtools</code> in a pipe to efficiently do multiple operations on an alignment file in a single command</li> </ul>"},{"location":"day1/alignment_advanced/#material","title":"Material","text":"<ul> <li><code>samtools</code> documentation</li> </ul>"},{"location":"day1/alignment_advanced/#exercises","title":"Exercises","text":""},{"location":"day1/alignment_advanced/#1-adding-readgroups","title":"1. Adding readgroups","text":"<p>During several steps of variant calling <code>gatk</code> uses read group information. For each read, this gives information on the sequencing platform, the library, the lane and of course the sample. Have a look at the description of the different levels of read group information <code>gatk</code> uses here. </p> <p>Exercise: The documentation mentions several read group fields that are used by <code>gatk</code>. Have a look at the <code>fastq</code> header. Does that give you the information that is required? Do we have that information for our sample? Can you specify it for our sample?</p> <p>Hint</p> <p>You can have a look at the first few entries in the <code>fastq</code> file with:</p> <pre><code>zcat mother_R1.fastq.gz | head\n</code></pre> Answer <p>Most of the information you should now based on the experimental design, the rest you can find in the fastq header:</p> <ul> <li><code>PL</code>: the platform. Should be quite obvious; you usually you have this information. For us, this would be <code>ILLUMINA</code></li> <li><code>SM</code>: the sample. All alignments that have reads coming from the same individual should have the same identifier in this field. For us, this would be <code>mother</code>. </li> <li><code>LB</code>: library identifier. Molecular duplicates only exist within a library. If a single library was sequenced on multiple lanes, it is important to track this information. In our case, we have sequenced only one library, so you can specify it with e.g. <code>lib1</code>. </li> <li><code>PU</code>: platform unit. This field is used to identify the sequencing lane. The documentation tells us we should specify it as <code>[FLOWCELL].[LANE].[SAMPLE BARCODE]</code>. The header of the first entry in our fastq file looks like this: <code>@H0164ALXX140820:2:1101:2136:40460/1</code>. Where the flowcell ID is <code>H0164</code> and the lane <code>2</code>. This formatting is specific to Broad Genomic Services pipelines, and not very common nowadays. Here the sample barcode is added to the flowcell ID, and is therefore specified as ALXX140820. We can therefore specify it with <code>H0164.2.ALXX140820</code>. </li> <li><code>ID</code>: read group id. If you don\u2019t have specific information on the flowcell and lane (specified with <code>PU</code>), you can use this field to specify a unique unit that is used for e.g. base quality score recalibration. This often a combination of a flow cell identifier and a lane. In our case this could be <code>H0164.2</code></li> </ul> <p>Note</p> <p>More modern output of an Illumina sequencer looks e.g. like this (example on Wikipedia):</p> <pre><code>@EAS139:136:FC706VJ:2:2104:15343:197393 1:Y:18:ATCACG\n</code></pre> <p>Here, e.g. the <code>PU</code> field would be <code>FC706VJ.2.ATCACG</code></p> <p>Exercise: Have a look at the documentation of <code>AddOrReplaceReadGroups</code>. Specify the required arguments, and run the command. Do this from a script called <code>B05_add_readgroups.sh</code> (in <code>~/project/scripts/B-mother_only</code>).</p> Answer <p>We can use the answers of the previous exercise, and use them in the command:</p> B05_add_readgroups.sh<pre><code>#!/usr/bin/env bash\n\ncd ~/project/results\n\ngatk AddOrReplaceReadGroups \\\n--INPUT alignments/mother.bam \\\n--OUTPUT alignments/mother.rg.bam \\\n--RGLB lib1 \\\n--RGPU H0164.2.ALXX140820 \\\n--RGPL ILLUMINA \\\n--RGSM mother \\\n--RGID H0164.2\n</code></pre> <p>Exercise: Compare the header and first alignments of <code>mother.bam</code> and <code>mother.rg.bam</code>. Notice any differences?</p> <p>Hint</p> <p>You can view the header with</p> <pre><code>samtools view -H &lt;alignment.bam&gt;\n</code></pre> <p>And the first few alignments with</p> <pre><code>samtools view &lt;alignment.bam&gt; | head\n</code></pre> Answer <p>Compared to the header of <code>mother.markdup.bam</code>, the header of <code>mother.markdup.rg.bam</code> contains an extra line starting with <code>@RG</code>:</p> <pre><code>@RG     ID:H0164.2      LB:lib1 PL:ILLUMINA     SM:mother       PU:H0164.2.ALXX140820\n</code></pre> <p>In the alignment records, a tag was added at the very end of each line: <code>RG:Z:H0164.2</code>. Note that all fields (<code>LB</code>, <code>PU</code>, etc.) are related to <code>ID</code>. So for each read only <code>ID</code> is specified and all other fields can be deducted from that. </p>"},{"location":"day1/alignment_advanced/#2-mark-duplicates","title":"2. Mark duplicates","text":"<p>Now that we have specified read groups, we can mark the duplicates with <code>gatk MarkDuplicates</code>. </p> <p>Exercise: Have a look at the documentation, and run <code>gatk MarkDuplicates</code> with the three required arguments. Do this from a script called <code>B06_mark_duplicates.sh</code> (in <code>~/project/scripts/B-mother_only</code>). </p> Answer B06_mark_duplicates.sh<pre><code>#!/usr/bin/env bash\n\ncd ~/project/results\n\ngatk MarkDuplicates \\\n--INPUT alignments/mother.rg.bam \\\n--OUTPUT alignments/mother.rg.md.bam \\\n--METRICS_FILE alignments/marked_dup_metrics_mother.txt \n</code></pre> <p>Exercise: Run <code>samtools flagstat</code> on the alignment file with marked duplicates, and write the output to a file called <code>mother.rg.md.bam.flagstat</code>. Create a script called <code>B07_get_alignment_stats_after_md.sh</code> (in <code>~/project/scripts/B-mother_only</code>). How many reads were marked as duplicate?</p> Answer B07_get_alignment_stats_after_md.sh<pre><code>#!/usr/bin/env bash\n\ncd ~/project/results/alignments\n\nsamtools flagstat mother.rg.md.bam &gt; mother.rg.md.bam.flagstat\n</code></pre> <p>Gives:</p> <p><pre><code>133477 + 0 in total (QC-passed reads + QC-failed reads)\n0 + 0 secondary\n317 + 0 supplementary\n17329 + 0 duplicates\n132892 + 0 mapped (99.56% : N/A)\n133160 + 0 paired in sequencing\n66580 + 0 read1\n66580 + 0 read2\n131470 + 0 properly paired (98.73% : N/A)\n131990 + 0 with itself and mate mapped\n\n585 + 0 singletons (0.44% : N/A)\n0 + 0 with mate mapped to a different chr\n0 + 0 with mate mapped to a different chr (mapQ&gt;=5)\n</code></pre> Which tells us that 17329 reads were marked as duplicate.</p>"},{"location":"day1/alignment_advanced/#3-indexing","title":"3. Indexing","text":"<p>To look up specific alignments, it is convenient to have your alignment file indexed. An indexing can be compared to a kind of \u2018phonebook\u2019 of your sequence alignment file. Indexing can be done with <code>samtools</code> as well, but it first needs to be sorted on coordinate (i.e. the alignment location). You can do it like this:</p> <pre><code>samtools index &lt;bam file&gt;\n</code></pre> <p>Exercise: Create a script called <code>B08_index_alignment.sh</code> (in <code>~/project/scripts/B-mother_only</code>) to perform the alignment.</p> Answer B08_index_alignment.sh<pre><code>#!/usr/bin/env bash\n\ncd ~/project/results/alignments/\n\nsamtools index mother.rg.md.bam\n</code></pre>"},{"location":"day1/alignment_advanced/#4-recap-mother-only","title":"4. Recap - mother only","text":"<p>Now we have performed now the following steps on the sample <code>mother</code>:</p> <ul> <li>Read alignment</li> <li>Adding readgroups</li> <li>Marking of duplicates</li> <li>Indexing</li> </ul> <p>Your <code>scripts</code> directory should look like this:</p> <pre><code>\u251c\u2500\u2500 A-prepare_references\n\u2502   \u251c\u2500\u2500 A01_download_course_data.sh\n\u2502   \u2514\u2500\u2500 A02_create_bwa_index.sh\n\u251c\u2500\u2500 B-mother_only\n\u2502   \u251c\u2500\u2500 B01_alignment.sh\n\u2502   \u251c\u2500\u2500 B02_get_alignment_statistics.sh\n\u2502   \u251c\u2500\u2500 B03_sort_alignment.sh\n\u2502   \u251c\u2500\u2500 B04_compress_alignment.sh\n\u2502   \u251c\u2500\u2500 B05_add_readgroups.sh\n\u2502   \u251c\u2500\u2500 B06_mark_duplicates.sh\n\u2502   \u251c\u2500\u2500 B07_get_alignment_stats_after_md.sh\n\u2502   \u2514\u2500\u2500 B08_index_alignment.sh\n\u2514\u2500\u2500 C-all_samples\n</code></pre>"},{"location":"day1/alignment_advanced/#5-apply-it-on-all-three-samples-with-pipes-and-loops","title":"5. Apply it on all three samples with pipes and loops","text":"<p>We now apply these steps to all three samples. In order to do that, we combine the alignment with the sorting and compression in one command. We can do that with piping the output of <code>bwa</code> to <code>samtools sort</code> and <code>samtools view</code>, like this:</p> <pre><code>SAMPLE=\"mother\"\n\nbwa mem data/reference/Homo_sapiens.GRCh38.dna.chromosome.20.fa \\\ndata/fastq/\"$SAMPLE\"_R1.fastq.gz \\\ndata/fastq/\"$SAMPLE\"_R2.fastq.gz \\\n| samtools sort \\\n| samtools view -bh &gt; results/alignments/\"$SAMPLE\".bam\n</code></pre> <p>Exercise: Make a directory in the scripts directory <code>C-all_samples</code> (so <code>~/project/scripts/C-all_samples</code>). In here, create a script called <code>C01_alignment_sorting_compression.sh</code>. Within that script use the above snippet to make a loop that performs the alignment, sorting and compression for all three samples (i.e. <code>mother</code>, <code>father</code> and <code>son</code>).</p> Answer <p>Your <code>scripts</code> directory should look like:</p> <pre><code>scripts\n\u251c\u2500\u2500 A-prepare_references\n\u2502   \u251c\u2500\u2500 A01_download_course_data.sh\n\u2502   \u2514\u2500\u2500 A02_create_bwa_index.sh\n\u251c\u2500\u2500 B-mother_only\n\u2502   \u251c\u2500\u2500 B01_alignment.sh\n\u2502   \u251c\u2500\u2500 B02_get_alignment_statistics.sh\n\u2502   \u251c\u2500\u2500 B03_sort_alignment.sh\n\u2502   \u251c\u2500\u2500 B04_compress_alignment.sh\n\u2502   \u251c\u2500\u2500 B05_add_readgroups.sh\n\u2502   \u251c\u2500\u2500 B06_mark_duplicates.sh\n\u2502   \u251c\u2500\u2500 B07_get_alignment_stats_after_md.sh\n\u2502   \u2514\u2500\u2500 B08_index_alignment.sh\n\u2514\u2500\u2500 C-all_samples\n    \u2514\u2500\u2500 C01_alignment_sorting_compression.sh\n</code></pre> <p>And the script: </p> C01_alignment_sorting_compression.sh<pre><code>#!/usr/bin/env bash\n\ncd ~/project\n\nfor SAMPLE in mother father son\ndo\n    bwa mem data/reference/Homo_sapiens.GRCh38.dna.chromosome.20.fa \\\n    data/fastq/\"$SAMPLE\"_R1.fastq.gz \\\n    data/fastq/\"$SAMPLE\"_R2.fastq.gz \\\n    | samtools sort \\\n    | samtools view -bh &gt; results/alignments/\"$SAMPLE\".bam\ndone\n</code></pre> <p>Now we continue with adding the readgroups. For each sample, we have to add specific information to the different readgroup fields. We can do that by looping over a tab delimited file with sample-specific information in each row. Let\u2019s create that tab-delimited file. </p> <p>Exercise Generate a tab-delimited file called <code>sample_rg_fields.txt</code> and store it in <code>~/project/results/</code>. In this file, each line should represent a sample (mother, father and son), and you specify the <code>SM</code>, <code>LB</code>, <code>PU</code> and <code>ID</code> fields. E.g., the first line (for \u2018mother\u2019) would look like:</p> <pre><code>mother  lib1    H0164.2.ALXX140820  H0164.2\n</code></pre> <p>Warning</p> <p>Make sure to add a newline (Enter) at the end of the file. Otherwise a loop will stop at the second-last line.</p> Answer <p>Your file should look like this:</p> <pre><code>mother  lib1    H0164.2.ALXX140820  H0164.2\nfather  lib2    H0164.3.ALXX140820  H0164.3\nson lib3    H0164.6.ALXX140820  H0164.6\n</code></pre> <p>Exercise Generate a script called <code>C02_add_readgroups.sh</code> (in <code>~/project/scripts/C-all_samples</code>) to loop over the tab-delimited file (have a look at the last exercise in Setup), and add the correct readgroups to the bam file of each sample with <code>gatk AddOrReplaceReadGroups</code>. </p> Hint <p>Try to just print the variables from a loop in order to check to see whether the loop performs according to your expectation. E.g.:</p> <pre><code>cd ~/project/results\n\ncat sample_rg_fields.txt | while read SAMPLE LB PU ID\ndo\n    echo $SAMPLE $LB $PU $ID\ndone\n</code></pre> Answer C02_add_readgroups.sh<pre><code>#!/usr/bin/env bash\n\ncd ~/project/results\n\ncat sample_rg_fields.txt | while read SAMPLE LB PU ID\ndo\n    gatk AddOrReplaceReadGroups \\\n    --INPUT alignments/\"$SAMPLE\".bam \\\n    --OUTPUT alignments/\"$SAMPLE\".rg.bam \\\n    --RGLB \"$LB\" \\\n    --RGPU \"$PU\" \\\n    --RGPL ILLUMINA \\\n    --RGSM \"$SAMPLE\" \\\n    --RGID \"$ID\"\ndone \n</code></pre> <p>As final step, we will mark the duplicates and perform the indexing for the three samples. </p> <p>Exercise: Generate two scripts called <code>C03_mark_duplicates.sh</code> and <code>C04_index_alignments.sh</code>, in which you loop over the sample names and  perform the respective calculations. You can use <code>B06_mark_duplicates.sh</code> and <code>B08_index_alignment.sh</code> as a template. </p> Answer C03_mark_duplicates.sh<pre><code>#!/usr/bin/env bash\n\ncd ~/project/results\n\nfor SAMPLE in mother father son\ndo\n    gatk MarkDuplicates \\\n    --INPUT alignments/\"$SAMPLE\".rg.bam \\\n    --OUTPUT alignments/\"$SAMPLE\".rg.md.bam \\\n    --METRICS_FILE alignments/marked_dup_metrics_\"$SAMPLE\".txt \ndone\n</code></pre> C04_index_alignment.sh<pre><code>#!/usr/bin/env bash\n\ncd ~/project/results\n\nfor SAMPLE in mother father son\ndo\n    samtools index alignments/\"$SAMPLE\".rg.md.bam\ndone  \n</code></pre>"},{"location":"day1/alignment_advanced/#6-recap-all-samples","title":"6. Recap - all samples","text":"<p>Now, we have performed on all three samples:</p> <ul> <li>Alignment</li> <li>Sorting</li> <li>Compression</li> <li>Adding readgroups</li> <li>Marking of duplicates</li> <li>Indexing</li> </ul> <p>Your scripts directory should look like this:</p> <pre><code>scripts\n\u251c\u2500\u2500 A-prepare_references\n\u2502   \u251c\u2500\u2500 A01_download_course_data.sh\n\u2502   \u2514\u2500\u2500 A02_create_bwa_index.sh\n\u251c\u2500\u2500 B-mother_only\n\u2502   \u251c\u2500\u2500 B01_alignment.sh\n\u2502   \u251c\u2500\u2500 B02_get_alignment_statistics.sh\n\u2502   \u251c\u2500\u2500 B03_sort_alignment.sh\n\u2502   \u251c\u2500\u2500 B04_compress_alignment.sh\n\u2502   \u251c\u2500\u2500 B05_add_readgroups.sh\n\u2502   \u251c\u2500\u2500 B06_mark_duplicates.sh\n\u2502   \u251c\u2500\u2500 B07_get_alignment_stats_after_md.sh\n\u2502   \u2514\u2500\u2500 B08_index_alignment.sh\n\u2514\u2500\u2500 C-all_samples\n    \u251c\u2500\u2500 C01_alignment_sorting_compression.sh\n    \u251c\u2500\u2500 C02_add_readgroups.sh\n    \u251c\u2500\u2500 C03_mark_duplicates.sh\n    \u2514\u2500\u2500 C04_index_alignment.sh\n</code></pre>"},{"location":"day1/introduction/","title":"Introduction","text":""},{"location":"day1/introduction/#learning-outcomes","title":"Learning outcomes","text":"<p>After having completed this chapter you will be able to:</p> <ul> <li>Describe the importance of studying variants</li> <li>Define a DNA mutation</li> <li>Illustrate the difference between a somatic mutation and a germline mutation</li> <li>Describe the two major types of small variants: SNPs and INDELs</li> <li>Explain why SNPs are the most used type of variant for genetic research</li> <li>Explain what haplotypes are and how they can capture more genetic information compared to single small variants</li> </ul>"},{"location":"day1/introduction/#material","title":"Material","text":"<p>Course introduction:</p> <p> Download the presentation</p> <p>Introduction to variant analysis:</p> <p> Download the presentation</p>"},{"location":"day1/reproducibility/","title":"Reproducibility","text":""},{"location":"day1/reproducibility/#learning-outcomes","title":"Learning outcomes","text":"<p>After having completed this chapter you will be able to:</p> <ul> <li>Understand the importance of reproducibility</li> <li>Apply some basic rules to support reproducibilty in computational research</li> </ul>"},{"location":"day1/reproducibility/#material","title":"Material","text":"<p> Download the presentation</p>"},{"location":"day1/reproducibility/#some-good-practices-for-reproducibility","title":"Some good practices for reproducibility","text":"<p>During the exercise you will be guided to adhere to the following basic principles for reproducibility:</p> <ol> <li>Execute the commands from a script in order to be able to trace back your steps</li> <li>Number scripts based on their order of execution (e.g. <code>01_download_reads.sh</code>)</li> <li>Give your scripts a descriptive and active name, e.g. <code>06_build_bowtie_index.sh</code></li> <li>Make your scripts specific, i.e. do not combine many different commands in the same script</li> <li>Refer to directories and variables at the beginning of the script</li> </ol> <p>Keep re-evaluating your code structure</p> <p>If you start a project it can be difficult to know what kind of analyses you are going to run, and how they interrelate. While working on a project, therefore re-evaluate readability of your project structure, and do not hesitate to change script numbering, names or contents. </p> <p>By adhering to these simple principles it will be relatively straightforward to re-do your analysis steps only based on the scripts, and will get you started to adhere to the Ten Simple Rules for Reproducible Computational Research. </p>"},{"location":"day1/reproducibility/#exercises","title":"Exercises","text":"<p>Throughout the exercises today and tomorrow we will work on three different \u2018subprojects\u2019:</p> <ul> <li>Preparing references by indexing</li> <li>Alignment and variant calling on one sample (\u2018mother\u2019)</li> <li>Alignment, variant calling and filtering on all samples</li> </ul> <p>We store the scripts required for these subprojects in different subdirectories of <code>~/project/scripts</code> named:</p> <ul> <li><code>A-prepare_references</code></li> <li><code>B-mother_only</code></li> <li><code>C-all_samples</code></li> </ul> <p>You can already create these directories now with:</p> <pre><code>cd ~/project/scripts/\n\nmkdir -p \\\nA-prepare_references \\\nB-mother_only \\\nC-all_samples\n</code></pre> <p>By the end of day 2 <code>~/project/scripts</code> should look (something) like this:</p> <pre><code>scripts\n\u251c\u2500\u2500 A_prepare_references\n\u2502   \u251c\u2500\u2500 A01_download_course_data.sh\n\u2502   \u251c\u2500\u2500 A02_create_bwa_index.sh\n\u2502   \u251c\u2500\u2500 A03_create_vcf_indices.sh\n\u2502   \u2514\u2500\u2500 A04_create_fasta_index.sh\n\u251c\u2500\u2500 B_mother_only\n\u2502   \u251c\u2500\u2500 B01_alignment.sh\n\u2502   \u251c\u2500\u2500 B02_get_alignment_statistics.sh\n\u2502   \u251c\u2500\u2500 B03_sort_alignment.sh\n\u2502   \u251c\u2500\u2500 B04_compress_alignment.sh\n\u2502   \u251c\u2500\u2500 B05_add_readgroups.sh\n\u2502   \u251c\u2500\u2500 B06_mark_duplicates.sh\n\u2502   \u251c\u2500\u2500 B07_get_alignment_stats_after_md.sh\n\u2502   \u251c\u2500\u2500 B08_index_alignment.sh\n\u2502   \u251c\u2500\u2500 B09_perform_bqsr.sh\n\u2502   \u251c\u2500\u2500 B10_run_haplotypecaller.sh\n\u2502   \u2514\u2500\u2500 B11_variants_to_table.sh\n\u2514\u2500\u2500 C_all_samples\n    \u251c\u2500\u2500 C01_alignment_sorting_compression.sh\n    \u251c\u2500\u2500 C02_add_readgroups.sh\n    \u251c\u2500\u2500 C03_mark_duplicates.sh\n    \u251c\u2500\u2500 C04_index_alignment.sh\n    \u251c\u2500\u2500 C05_perform_bqsr.sh\n    \u251c\u2500\u2500 C06_run_haplotypecaller.sh\n    \u251c\u2500\u2500 C07_create_genomicsdb.sh\n    \u251c\u2500\u2500 C08_genotype_gvcfs.sh\n    \u251c\u2500\u2500 C09_select_SNPs.sh\n    \u251c\u2500\u2500 C10_select_INDELs.sh\n    \u251c\u2500\u2500 C11_filter_SNPs.sh\n    \u251c\u2500\u2500 C12_filter_INDELs.sh\n    \u251c\u2500\u2500 C13_merge_filtered.sh\n    \u251c\u2500\u2500 C14_extract_mother_only.sh\n    \u251c\u2500\u2500 C15_evaluate_concordance.sh\n    \u251c\u2500\u2500 C16_extract_mother_before_filtering.sh\n    \u2514\u2500\u2500 C17_evaluate_concordance_before_filtering.sh\n</code></pre>"},{"location":"day1/server_login/","title":"Setup","text":""},{"location":"day1/server_login/#learning-outcomes","title":"Learning outcomes","text":"<p>Note</p> <p>You might already be able to do some or all of these learning outcomes. If so, you can go through the corresponding exercises quickly. The general aim of this chapter is to work comfortably on a remote server by using the command line.</p> <p>After having completed this chapter you will be able to:</p> <ul> <li>Use the command line to:<ul> <li>Make a directory</li> <li>Change file permissions to \u2018executable\u2019</li> <li>Run a <code>bash</code> script</li> <li>Pipe data from and to a file or other executable</li> </ul> </li> <li>Program a loop in <code>bash</code></li> </ul> <p>Choose your platform</p> <p>In this part we will show you how to access the cloud server, or setup your computer to do the exercises with conda or with Docker.</p> <p>If you are doing the course with a teacher, you will have to login to the remote server. Therefore choose:</p> <ul> <li>Cloud notebook</li> </ul> <p>If you are doing this course independently (i.e. without a teacher) choose either:</p> <ul> <li>conda</li> <li>Docker</li> </ul> Cloud serverDockerconda <p>If you have a conda installation on your local computer, you can install the required software using conda.</p> <p>You can build the environment from environment.yml</p> <p>Generate the conda environment like this:</p> <pre><code>conda env create --name ngs-tools -f environment.yml\n</code></pre> <p>The <code>yaml</code> file probably only works for Linux systems</p> <p>If you want to use the conda environment on a different OS, use:</p> <pre><code>conda create -n ngs-tools python=3.8\n\nconda activate ngs-tools\n\nconda install -y -c bioconda \\\nsamtools \\\nbwa \\\nsnpeff \\\ngatk4 \\\nr-base\n</code></pre> <p>This will create the conda environment <code>ngs-tools</code></p> <p>Activate it like so:</p> <pre><code>conda activate ngs-tools\n</code></pre> <p>After successful installation and activating the environment all the software required to do the exercises should be available.</p>"},{"location":"day1/server_login/#exercises","title":"Exercises","text":""},{"location":"day1/server_login/#first-login","title":"First login","text":"<p>If you are participating in this course with a teacher, you have received a link and a password. Copy-paste the link (including the port, e.g.: <code>http://12.345.678.91:10002</code>) in your browser. This should result in the following page:</p> <p> </p> <p>Info</p> <p>The link gives you access to a web version of Visual Studio Code. This is a powerful code editor that you can also use a local application on your computer. </p> <p>Type in the password that was provided to you by the teacher. Now let\u2019s open the terminal. You can do that with Ctrl+`. Or by clicking Application menu &gt; Terminal &gt; New Terminal:</p> <p> </p> <p>For a.o. efficiency and reproducibility it makes sense to execute your commands from a script. With use of the \u2018new file\u2019 button:</p> <p> </p>"},{"location":"day1/server_login/#material","title":"Material","text":"<ul> <li>Instructions to install docker</li> <li>Instructions to set up to container</li> </ul>"},{"location":"day1/server_login/#exercises_1","title":"Exercises","text":""},{"location":"day1/server_login/#first-login_1","title":"First login","text":"<p>Docker can be used to run an entire isolated environment in a container. This means that we can run the software with all its dependencies required for this course locally in your computer. Independent of your operating system.</p> <p>In the video below there\u2019s a tutorial on how to set up a docker container for this course. Note that you will need administrator rights, and that if you are using Windows, you need the latest version of Windows 10.</p> <p></p> <p>The command to run the environment required for this course looks like this (in a terminal):</p> <p>Modify the script</p> <p>Modify the path after <code>-v</code> to the working directory on your computer before running it.</p> <pre><code>docker run \\\n--rm \\\n-p 8443:8443 \\\n-e PUID=1000 \\\n-e PGID=1000 \\\n-e DEFAULT_WORKSPACE=/config/project \\\n-v $PWD:/config/project \\\ngeertvangeest/ngs-variants-vscode\n</code></pre> <p>If this command has run successfully, use your browser to navigate to port 8443 on your local machine:</p> <pre><code>http://127.0.0.1:8443\n</code></pre> <p>The option <code>-v</code> mounts a local directory in your computer to the directory <code>/config/project</code> in the docker container. In that way, you have files available both in the container and on your computer. Use this directory on your computer to e.g. visualise data with IGV. Change the first path to a path on your computer that you want to use as a working directory.</p> <p>Don\u2019t mount directly in the home dir</p> <p>Don\u2019t directly mount your local directory to the home directory (<code>/root</code>). This will lead to unexpected behaviour.</p> <p>The part <code>geertvangeest/ngs-variants-vscode</code> is the image we are going to load into the container. The image contains all the information about software and dependencies needed for this course. When you run this command for the first time it will download the image. Once it\u2019s on your computer, it will start immediately.</p>"},{"location":"day1/server_login/#a-unix-command-line-interface-cli-refresher","title":"A UNIX command line interface (CLI) refresher","text":"<p>Most bioinformatics software are UNIX based and are executed through the CLI. When working with NGS data, it is therefore convenient to improve your knowledge on UNIX. For this course, we need basic understanding of UNIX CLI, so here are some exercises to refresh your memory. </p> <p>If you need some reminders of the commands, here\u2019s a link to a UNIX command line cheat sheet:</p> <p> UNIX cheat sheet</p>"},{"location":"day1/server_login/#make-a-new-directory","title":"Make a new directory","text":"<p>Make a directory <code>scripts</code> within <code>~/project</code> and make it your current directory.</p> Answer <pre><code>cd ~/project\nmkdir scripts\ncd scripts\n</code></pre>"},{"location":"day1/server_login/#file-permissions","title":"File permissions","text":"<p>Generate an empty script in your newly made directory <code>~/project/scripts</code> like this:</p> <pre><code>touch new_script.sh\n</code></pre> <p>Add a command to this script that writes \u201cSIB courses are great!\u201d (or something you can better relate to.. ) to stdout, and try to run it.</p> Answer <p>Generate a script as described above. The script should look like this:</p> <pre><code>#!/usr/bin/env bash\n\necho \"SIB courses are great!\"\n</code></pre> <p>Usually, you can run it like this:</p> <pre><code>./new_script.sh\n</code></pre> <p>But there\u2019s an error:</p> <pre><code>bash: ./new_script.sh: Permission denied\n</code></pre> <p>Why is there an error?</p> <p>Hint</p> <p>Use <code>ls -lh new_script.sh</code> to check the permissions.</p> Answer <pre><code>ls -lh new_script.sh\n</code></pre> <p>gives:</p> <pre><code>-rw-r--r--  1 user  group    51B Nov 11 16:21 new_script.sh\n</code></pre> <p>There\u2019s no <code>x</code> in the permissions string. You should change at least the permissions of the user.</p> <p>Make the script executable for yourself, and run it.</p> Answer <p>Change permissions:</p> <pre><code>chmod u+x new_script.sh\n</code></pre> <p><code>ls -lh new_script.sh</code> now gives:</p> <pre><code>-rwxr--r--  1 user  group    51B Nov 11 16:21 new_script.sh\n</code></pre> <p>So it should be executable:</p> <pre><code>./new_script.sh\n</code></pre> <p>More on <code>chmod</code> and file permissions here.</p>"},{"location":"day1/server_login/#redirection-and","title":"Redirection: <code>&gt;</code> and <code>|</code>","text":"<p>In the root directory (go there like this: <code>cd /</code>) there are a range of system directories and files. Write the names of all directories and files to a file called <code>system_dirs.txt</code> in your working directory.</p> Answer <pre><code>ls / &gt; ~/project/system_dirs.txt\n</code></pre> <p>The command <code>wc -l</code> counts the number of lines, and can read from stdin. Make a one-liner with a pipe <code>|</code> symbol to find out how many system directories and files there are.</p> Answer <pre><code>ls / | wc -l\n</code></pre>"},{"location":"day1/server_login/#variables","title":"Variables","text":"<p>Store <code>system_dirs.txt</code> as variable (like this: <code>VAR=variable</code>), and use <code>wc -l</code> on that variable to count the number of lines in the file.</p> Answer <pre><code>FILE=~/project/system_dirs.txt\nwc -l $FILE\n</code></pre>"},{"location":"day1/server_login/#shell-scripts","title":"shell scripts","text":"<p>Make a shell script that automatically counts the number of system directories and files.</p> Answer <p>Make a script called e.g. <code>current_system_dirs.sh</code>: <pre><code>#!/usr/bin/env bash\ncd /\nls | wc -l\n</code></pre></p>"},{"location":"day1/server_login/#loops","title":"Loops","text":"<p>If you want to run the same command on a range of arguments, it\u2019s not very convenient to type the command for each individual argument. For example, you could write <code>dog</code>, <code>fox</code>, <code>bird</code> to stdout in a script like this:</p> <pre><code>#!/usr/bin/env bash\n\necho dog\necho fox\necho bird\n</code></pre> <p>However, if you want to change the command (add an option for example), you would have to change it for all the three command calls. Amongst others for that reason, you want to write the command only once. You can do this with a for-loop, like this:</p> <pre><code>#!/usr/bin/env bash\n\nANIMALS=\"dog fox bird\"\n\nfor animal in $ANIMALS\ndo\n  echo $animal\ndone\n</code></pre> <p>Which results in:</p> <pre><code>dog\nfox\nbird\n</code></pre> <p>Write a shell script that removes all the letters \u201ce\u201d from a list of words.</p> <p>Hint</p> <p>Removing the letter \u201ce\u201d from a string can be done with <code>tr</code> like this: <pre><code>word=\"test\"\necho $word | tr -d \"e\"\n</code></pre></p> <p>Which would result in:</p> <pre><code>tst\n</code></pre> Answer <p>Your script should e.g. look like this (I\u2019ve added some awesome functionality):</p> <pre><code>#!/usr/bin/env bash\n\nWORDLIST=\"here is a list of words resulting in a sentence\"\n\nfor word in $WORDLIST\ndo\n  echo \"'$word' with e's removed looks like:\"\n  echo $word | tr -d \"e\"\ndone\n</code></pre> <p>resulting in:</p> <pre><code>'here' with e's removed looks like:\nhr\n'is' with e's removed looks like:\nis\n'a' with e's removed looks like:\na\n'list' with e's removed looks like:\nlist\n'of' with e's removed looks like:\nof\n'words' with e's removed looks like:\nwords\n'resulting' with e's removed looks like:\nrsulting\n'in' with e's removed looks like:\nin\n'a' with e's removed looks like:\na\n'sentence' with e's removed looks like:\nsntnc\n</code></pre> <p>Like you might be used to in <code>R</code> or <code>python</code> you can also loop over lines in files. This can be convenient if you have for example a set of parameters in each line of a file. </p> <p>Create a tab-delimited file <code>animals.txt</code> with the following contents:</p> <pre><code>dog retrieves   4\nfox jumps   4\nbird    flies   2\n</code></pre> <p>Hint</p> <p>If you\u2019re having trouble typing the actual \u2018tabs\u2019 you can also download the file here</p> <p>With unix shell you can loop over the lines of that file and store each column as a variable. Below, the three columns in the tab delimited file are stored in the variables <code>$animal</code>, <code>$behaviour</code> and <code>$leg_number</code>:</p> <pre><code>cat animals.txt | while read animal behaviour leg_number\ndo\n    #something here\ndone\n</code></pre> <p>Exercise: Modify the script in such a way that it writes the strings that are stored in the variables at each line to stdout. </p> Done <pre><code>cat animals.txt | while read animal behaviour leg_number\ndo\n    echo \"The $animal $behaviour, and has $leg_number legs\" \ndone\n</code></pre>"},{"location":"day2/annotation/","title":"Annotation","text":""},{"location":"day2/annotation/#learning-outcomes","title":"Learning outcomes","text":"<p>After having completed this chapter you will be able to:</p> <ul> <li>Describe the aims of variant annotation</li> <li>Explain how variants are ranked in order of importance</li> <li>Explain how splice variation affects variant annotation</li> <li>Perform a variant annotation with <code>snpEff</code></li> <li>Interpret the report generated by <code>snpEff</code></li> <li>Explain how variant annotation can be added to a <code>vcf</code> file</li> </ul>"},{"location":"day2/annotation/#material","title":"Material","text":"<p> Download the presentation</p>"},{"location":"day2/annotation/#exercises","title":"Exercises","text":"<p>To use the human genome as a reference, we have downloaded the database with:</p> <p>No need to download, it\u2019s already downloaded for you</p> <pre><code># don't run this. It's already downloaded for you\nsnpEff download -v GRCh38.99\n</code></pre> <p>You can run snpEff like so:</p> <pre><code>mkdir annotation\n\nsnpEff -Xmx4g \\\n-v \\\n-dataDir /data/ \\\nGRCh38.99 \\\n&lt;filtered_variants.vcf&gt; \\\n&gt; &lt;annotated_variants.vcf&gt;\n</code></pre> <p>Exercise: Run the command on the filtered vcf (<code>trio.filtered.vcf</code>) using a script called <code>C18_annotate_snpEff.sh</code>. Check out the html file (<code>snpEff_summary.html</code>). Try to answer these questions:</p> <p>A. How many effects were calculated?</p> <p>B. How many variants are in the vcf?</p> <p>C. Why is this different?</p> <p>D. How many effects result in a missense mutation?</p> Answer <p>Your script:</p> C18_annotate_snpEff.sh<pre><code>#!/usr/bin/env bash\n\ncd ~/project/results/variants\n\nsnpEff -Xmx4g \\\n-v \\\n-dataDir /data/ \\\nGRCh38.99 \\\ntrio.filtered.vcf \\\n&gt; trio.filtered.snpeff.vcf\n</code></pre> <p>A. There were 10,357 effects calculated.</p> <p>B. There are only 556 variants in the vcf.</p> <p>C. This means that there are multiple effects per variant. snpEff calculates effects for each splice variant, and therefore the number of effects are a multitude of the number of variants.</p> <p>D. Two effects result in a missense mutation.</p> <p>You can (quick and dirty) query the annotated vcf for the missense mutation with <code>grep</code>.</p> <p>Exercise: Find the variant causing the missense mutation (the line contains the string <code>missense</code>). And answer the following questions:</p> Hint <pre><code>grep missense trio.filtered.snpeff.vcf \n</code></pre> <p>Run the command and have a look at the SnpEff ANN field documentation. Answer the following questions:</p> <p>A. How are the SNP annotations stored in the vcf?</p> <p>B. What are the genotypes of the individuals?</p> <p>C. Which amino acid change does it cause?</p> Answer <p>Find the line with the missense mutation like this:</p> <pre><code>grep missense annotation/trio.filtered.snpeff.vcf\n</code></pre> <p>This results in (truncated long line, scroll to the right to see more):</p> <pre><code>chr20   10049540        .       T       A       220.29  PASS    AC=1;AF=0.167;AN=6;BaseQRankSum=-6.040e-01;DP=85;ExcessHet=3.0103;FS=0.000;MLEAC=1;MLEAF=0.167;MQ=60.00;MQRankSum=0.00;QD=8.16;ReadPosRankSum=0.226;SOR=0.951;ANN=A|missense_variant|MODERATE|ANKEF1|ENSG00000132623|transcript|ENST00000378392.6|protein_coding|7/11|c.971T&gt;A|p.Leu324Gln|1426/5429|971/2331|324/776||,A|missense_variant|MODERATE|ANKEF1|ENSG00000132623|transcript|ENST00000378380.4|protein_coding|6/10|c.971T&gt;A|p.Leu324Gln|1300/5303|971/2331|324/776||       GT:AD:DP:GQ:PL  0/0:34,0:34:99:0,102,1163       0/1:17,10:27:99:229,0,492       0/0:24,0:24:72:0,72,811\n</code></pre> <p>A. SNP annotations are stored in the INFO field, starting with <code>ANN=</code></p> <p>B. The genotypes are homozygous reference for the father and son, and heterozygous for the mother. (find the order of the samples with <code>grep ^#CHROM</code>)</p> <p>C. The triplet changes from cTg to cAg, resulting in a change from Leu (Leucine) to Gln (Glutamine).</p>"},{"location":"day2/filtering_evaluation/","title":"Filtering & evaluation","text":""},{"location":"day2/filtering_evaluation/#learning-outcomes","title":"Learning outcomes","text":"<p>After having completed this chapter you will be able to:</p> <ul> <li>Explain why using Variant Quality Score Recalibration (VQSR) for filtering variants can outperform hard filtering </li> <li>Perform hard filtering on both SNPs and INDELs separately by using <code>gatk SelectVariants</code> in combination with <code>gatk VariantFiltration</code></li> <li>Perform concordance between called variants and a truth set and evaluate performance of a variant calling workflow</li> </ul>"},{"location":"day2/filtering_evaluation/#material","title":"Material","text":"<p> Download the presentation</p>"},{"location":"day2/filtering_evaluation/#exercises","title":"Exercises","text":""},{"location":"day2/filtering_evaluation/#1-hard-filtering","title":"1. Hard filtering","text":"<p>The developers of <code>gatk</code> strongly advise to do Variant Quality Score Recalibration (VQSR) for filtering SNPs and INDELs. However, this is not always possible. For example, in the case of limited data availability and/or in the case you are working with non-model organisms and/or in the case you are a bit lazy and okay with a number of false positives.</p> <p>Our dataset is too small to apply VQSR. We will therefore do hard filtering instead.</p>"},{"location":"day2/filtering_evaluation/#splitting-snps-and-indels","title":"Splitting SNPs and INDELs","text":"<p>First, filtering thresholds are usually different for SNPs and INDELs. Therefore, we will split <code>trio.vcf</code> into two vcfs, one containg only SNPs, and one containing only INDELs. You can extract all the SNP records in our trio vcf like this:</p> <pre><code>cd ~/project/results\n\ngatk SelectVariants \\\n--variant variants/trio.vcf \\\n--select-type-to-include SNP \\\n--output variants/trio.SNP.vcf\n</code></pre> <p>Exercise: Check out the documentation of <code>gatk SelectVariants</code>, and:</p> <ul> <li>Figure out what you\u2019ll need to write at <code>--select-type-to-include</code> if you want to select only INDELS.</li> <li>Make a script (named <code>C09_select_SNPs.sh</code>) to generate a vcf with only the SNPs</li> <li>Make a script (named <code>C10_select_INDELs.sh</code>) to generate a second vcf with only the INDELs from <code>trio.vcf</code>.</li> </ul> Answer <p>You will need to fill in <code>INDEL</code> at <code>--select-type-to-include</code> to filter for INDELs.</p> <p>To get the SNPs you can run the command above:</p> C09_select_SNPs.sh<pre><code>#!/usr/bin/env bash\n\ncd ~/project\n\ngatk SelectVariants \\\n--variant results/variants/trio.vcf \\\n--select-type-to-include SNP \\\n--output results/variants/trio.SNP.vcf\n</code></pre> <p>To get the INDELs you\u2019ll need to change <code>--select-type-to-include</code> to <code>INDEL</code>:</p> C10_select_INDELs.sh<pre><code>#!/usr/bin/env bash\n\ncd ~/project\n\ngatk SelectVariants \\\n--variant results/variants/trio.vcf \\\n--select-type-to-include INDEL \\\n--output results/variants/trio.INDEL.vcf\n</code></pre>"},{"location":"day2/filtering_evaluation/#filtering-snps","title":"Filtering SNPs","text":"<p>The command <code>gatk VariantFiltration</code> enables you to filter for both the INFO field (per variant) and FORMAT field (per genotype). For now we\u2019re only interested in filtering variants. Below you can find the command to hard-filter the SNP variants on some sensible thresholds (that are explained here).</p> <pre><code>gatk VariantFiltration \\\n--variant variants/trio.SNP.vcf \\\n--filter-expression \"QD &lt; 2.0\"              --filter-name \"QD2\" \\\n--filter-expression \"QUAL &lt; 30.0\"           --filter-name \"QUAL30\" \\\n--filter-expression \"SOR &gt; 3.0\"             --filter-name \"SOR3\" \\\n--filter-expression \"FS &gt; 60.0\"             --filter-name \"FS60\" \\\n--filter-expression \"MQ &lt; 40.0\"             --filter-name \"MQ40\" \\\n--filter-expression \"MQRankSum &lt; -12.5\"     --filter-name \"MQRankSum-12.5\" \\\n--filter-expression \"ReadPosRankSum &lt; -8.0\" --filter-name \"ReadPosRankSum-8\" \\\n--output variants/trio.SNP.filtered.vcf\n</code></pre> <p>Exercise: Run the filtering command above in a script called <code>C11_filter_SNPs.sh</code>. Did it affect the number of records in the vcf?</p> <p>Hint</p> <p>You can check out the number of records in a vcf with:</p> <pre><code>grep -v \"^#\" &lt;variants.vcf&gt; | wc -l\n</code></pre> Answer <p>Your script:</p> C11_filter_SNPs.sh<pre><code>#!/usr/bin/env bash\n\ncd ~/project/results/variants\n\ngatk VariantFiltration \\\n--variant trio.SNP.vcf \\\n--filter-expression \"QD &lt; 2.0\"              --filter-name \"QD2\" \\\n--filter-expression \"QUAL &lt; 30.0\"           --filter-name \"QUAL30\" \\\n--filter-expression \"SOR &gt; 3.0\"             --filter-name \"SOR3\" \\\n--filter-expression \"FS &gt; 60.0\"             --filter-name \"FS60\" \\\n--filter-expression \"MQ &lt; 40.0\"             --filter-name \"MQ40\" \\\n--filter-expression \"MQRankSum &lt; -12.5\"     --filter-name \"MQRankSum-12.5\" \\\n--filter-expression \"ReadPosRankSum &lt; -8.0\" --filter-name \"ReadPosRankSum-8\" \\\n--output trio.SNP.filtered.vcf\n</code></pre> <p>There are no differences in the number of records:</p> <pre><code>grep -v \"^#\" variants/trio.SNP.vcf | wc -l\n</code></pre> <p>and</p> <pre><code>grep -v \"^#\" variants/trio.SNP.filtered.vcf | wc -l\n</code></pre> <p>both give 446.</p> <p>However, there are SNPs filtered out, by changing the <code>FILTER</code> column. You can check the number of records with PASS by:</p> <pre><code>grep -v \"^#\" variants/trio.SNP.filtered.vcf | cut -f 7 | sort | uniq -c\n</code></pre> <p>Giving:</p> <pre><code>441 PASS\n2 QD2;SOR3\n3 SOR3\n</code></pre>"},{"location":"day2/filtering_evaluation/#filtering-indels","title":"Filtering INDELs","text":"<p>A command with sensible parameters to do a first iteration of hard filtering the INDELs would be:</p> <pre><code>gatk VariantFiltration \\\n--variant variants/trio.INDEL.vcf \\\n--filter-expression \"QD &lt; 2.0\"                  --filter-name \"QD2\" \\\n--filter-expression \"QUAL &lt; 30.0\"               --filter-name \"QUAL30\" \\\n--filter-expression \"FS &gt; 200.0\"                --filter-name \"FS200\" \\\n--filter-expression \"ReadPosRankSum &lt; -20.0\"    --filter-name \"ReadPosRankSum-20\" \\\n--output variants/trio.INDEL.filtered.vcf\n</code></pre> <p>Exercise: Run the command from a script called <code>C12_filter_INDELs.sh</code> and figure out how many variants are filtered out.</p> <p>Hint</p> <p>You can use this command from the answer to the previous exercise:</p> <pre><code>grep -v \"^#\" &lt;variants.vcf&gt; | cut -f 7 | sort | uniq -c\n</code></pre> <p>to see how many INDELs were filtered out.</p> Answer <p>Your script:</p> C12_filter_INDELs.sh<pre><code>#!/usr/bin/env bash\n\ncd ~/project/results/variants\n\ngatk VariantFiltration \\\n--variant trio.INDEL.vcf \\\n--filter-expression \"QD &lt; 2.0\"                  --filter-name \"QD2\" \\\n--filter-expression \"QUAL &lt; 30.0\"               --filter-name \"QUAL30\" \\\n--filter-expression \"FS &gt; 200.0\"                --filter-name \"FS200\" \\\n--filter-expression \"ReadPosRankSum &lt; -20.0\"    --filter-name \"ReadPosRankSum-20\" \\\n--output trio.INDEL.filtered.vcf\n</code></pre> <p>And check out the contents of the <code>FILTER</code> column: </p> <pre><code>grep -v \"^#\" variants/trio.INDEL.filtered.vcf | cut -f 7 | sort | uniq -c\n</code></pre> <p>gives:</p> <pre><code>110 PASS\n</code></pre> <p>So no variants are filtered out.</p>"},{"location":"day2/filtering_evaluation/#merging-filtered-snps-and-indels","title":"Merging filtered SNPs and INDELs","text":"<p>Now that we have filtered the INDELs and SNPs separately, we can merge them again with this command:</p> <pre><code>gatk MergeVcfs \\\n--INPUT &lt;input1.vcf&gt; \\\n--INPUT &lt;input2.vcf&gt; \\\n--OUTPUT &lt;merged.vcf&gt;\n</code></pre> <p>Exercise: Run this command from a script called <code>C13_merge_filtered.sh</code> to merge the vcfs (<code>trio.SNP.filtered.vcf</code> and <code>trio.INDEL.filtered.vcf</code>).</p> Answer C13_merged_filtered.sh<pre><code>#!/usr/bin/env bash\n\ncd ~/project/results/variants\n\ngatk MergeVcfs \\\n--INPUT trio.SNP.filtered.vcf \\\n--INPUT trio.INDEL.filtered.vcf \\\n--OUTPUT trio.filtered.vcf\n</code></pre>"},{"location":"day2/filtering_evaluation/#2-evaluation-by-concordance","title":"2. Evaluation by concordance","text":"<p>For this region we have a highly curated truth set for the mother available. It originates from the Illumina Platinum truth set. You can find it at <code>data/variants/NA12878.vcf.gz</code></p> <p>To check how well we did, we\u2019d first need to extract a vcf with only the information of the mother.</p> <p>Exercise: Generate a script called <code>C14_extract_mother_only.sh</code> to extract variants that have at least one alternative allele in the mother from <code>variants/trio.filtered.vcf</code>. Use <code>gatk SelectVariants</code> with the arguments:</p> <ul> <li><code>--sample-name mother</code></li> <li><code>--exclude-non-variants</code></li> <li><code>--remove-unused-alternates</code></li> </ul> <p>In addition to the required arguments.</p> Answer C14_extract_mother_only.sh<pre><code>#!/usr/bin/env bash\n\ncd ~/project/results/variants\n\ngatk SelectVariants \\\n--variant trio.filtered.vcf \\\n--sample-name mother \\\n--exclude-non-variants \\\n--remove-unused-alternates \\\n--output mother.trio.filtered.vcf\n</code></pre> <p>Exercise:</p> <p>A. How many variants are in the extracted vcf? How many of those are filtered out?</p> <p>B. Compare our vcf with the curated truth set with the command below from a script called <code>C15_evaluate_concordance.sh</code>. How many SNPs didn\u2019t we detect?</p> <pre><code>gatk Concordance \\\n--evaluation variants/mother.trio.filtered.vcf \\\n--truth data/variants/NA12878.vcf.gz \\\n--intervals chr20:10018000-10220000 \\\n--summary variants/concordance.mother.trio.filtered\n</code></pre> Answer <p>To get the number of records per FILTER, we run:</p> <pre><code>grep -v \"^#\" variants/mother.trio.filtered.vcf | cut -f 7 | sort | uniq -c\n</code></pre> <p>gives:</p> <pre><code>407 PASS\n2 SOR3\n</code></pre> <p>So two records were filtered out, based on the Symmetric Odds Ratio (issues with strand bias).</p> <p>Your script to evaluate the concordance:</p> C15_evaluate_concordance.sh<pre><code>#!/usr/bin/env bash\n\ncd ~/project\n\ngatk Concordance \\\n--evaluation results/variants/mother.trio.filtered.vcf \\\n--truth data/variants/NA12878.vcf.gz \\\n--intervals chr20:10018000-10220000 \\\n--summary results/variants/concordance.mother.trio.filtered\n</code></pre> <p>Check out the output with <code>cat</code>:</p> <pre><code>cat variants/concordance.mother.trio.filtered\n</code></pre> <p>gives:</p> <pre><code>type    TP      FP      FN      RECALL  PRECISION\nSNP     319     5       9       0.973   0.985\nINDEL   63      20      6       0.913   0.759\n</code></pre> <p>Showing that there were 9 false negatives, i.e. SNPs we didn\u2019t detect.</p> <p>Recall &amp; precision</p> <p>More info on the definition of recall and precision on this wikipedia page</p> <p>Exercise: Check out the concordance of the mother with the truth set before filtering. Do this by generating two scripts:</p> <ul> <li><code>C16_extract_mother_before_filtering.sh</code>: to run <code>gatk SelectVariants</code> in order to get only variants from the mother from the unfiltered <code>trio.vcf</code>. </li> <li><code>C17_evaluate_concordance_before_filtering.sh</code>: to run <code>gatk Concordance</code> on the selected variants. </li> </ul> <p>Did filtering improve the recall or precision?</p> <p>Note</p> <p>We did the filtering on <code>trio.vcf</code>, therefore, you first have to extract the records that only apply to the mother by using <code>gatk SelectVariants</code>.</p> <p>Also note that <code>trio.vcf</code> contains records other than SNPs and INDELs. Use <code>--select-type-to-include</code> to select only SNPs and INDELs.</p> Answer <p>First select only SNPs and INDELs from the mother from the unfiltered vcf:</p> C16_extract_mother_before_filtering.sh<pre><code>#!/usr/bin/env bash\n\ncd ~/project/results/variants\n\ngatk SelectVariants \\\n--variant trio.vcf \\\n--sample-name mother \\\n--exclude-non-variants \\\n--remove-unused-alternates \\\n--select-type-to-include INDEL \\\n--select-type-to-include SNP \\\n--output mother.trio.vcf\n</code></pre> <p>Get the concordance with the truth set:</p> C17_evaluate_concordance_before_filtering.sh<pre><code>#!/usr/bin/env bash\n\ncd ~/project\n\ngatk Concordance \\\n--evaluation results/variants/mother.trio.vcf \\\n--truth data/variants/NA12878.vcf.gz \\\n--intervals chr20:10018000-10220000 \\\n--summary results/variants/concordance.mother.trio\n</code></pre> <p>Which gives:</p> <pre><code>type    TP      FP      FN      RECALL  PRECISION\nSNP     319     7       9       0.973   0.979\nINDEL   63      20      6       0.913   0.759\n</code></pre> <p>The precision for SNPs is slightly lower. Due to filtering, we removed two false positives.</p>"},{"location":"day2/variant_calling/","title":"Variant calling","text":""},{"location":"day2/variant_calling/#learning-outcomes","title":"Learning outcomes","text":"<p>After having completed this chapter you will be able to:</p> <ul> <li>Perform basic calculations regarding the genotype likelihood of individual variants</li> <li>Follow <code>gatk</code> best practices workflow to perform a variant analysis by:<ul> <li>Calling variants with <code>gatk HaplotypeCaller</code></li> <li>Combining multiple <code>vcf</code> files into a single <code>vcf</code> file</li> </ul> </li> <li>Perform basic operations to get statistics of a <code>vcf</code> file</li> </ul>"},{"location":"day2/variant_calling/#material","title":"Material","text":"<p>The paper on genomic variant call format (gVCF)</p> <p>GATK best practices germline short variant workflow:</p>"},{"location":"day2/variant_calling/#exercises","title":"Exercises","text":""},{"location":"day2/variant_calling/#1-variant-calling","title":"1. Variant calling","text":""},{"location":"day2/variant_calling/#calculating-pl-and-gq-by-hand","title":"Calculating PL and GQ by hand","text":"<p>Here\u2019s a function in R to calculate genotype likelihoods as described in Li H.  Bioinformatics. 2011;27:2987\u201393 (assuming equal base error probabilities for all reads):</p> <pre><code>genotype_likelihood &lt;- function(m,g,e,ref,alt){\n  (((m-g)*e+g*(1-e))^alt * ((m-g)*(1-e)+g*e)^ref)/(m^(ref+alt))\n}\n</code></pre> <p>Where:</p> <ul> <li><code>m</code> : ploidy</li> <li><code>g</code> : number of alternative alleles</li> <li><code>e</code> : base error probability</li> <li><code>ref</code> : number of reference alleles counted</li> <li><code>alt</code> : number of alternative alleles counted</li> </ul> <p>Exercise: In the <code>scripts</code> directory, create a script called <code>calculate_genotype_likelihoods.R</code>. Copy-paste the above function to the script, and use it to calculate the three genotype likelihoods (for g = 0, g = 1 and g = 2) for a case where we count 22 reference alleles and 4 alternative alleles (so a coverage of 26), and base error probability of 0.01. Calculate the PL values (<code>-10*log10(likelihood)</code>) for each genotype. </p> <p>Using VScode with R</p> <p>In order to easily interact with your R script, you can do the following:</p> <ul> <li>Open the R script in VS code</li> <li>In the terminal, type <code>R</code> to start the R console</li> <li>Select the code you\u2019d like to run in the R script</li> <li>Type Ctrl+Enter to send it to the console</li> <li>After you have finished, type <code>quit()</code> in the R console. </li> </ul> Answer <pre><code># For g = 0 (i.e. 0 alternative alleles)\n-10*log10(genotype_likelihood(m = 2, g= 0, e = 0.01, ref = 22, alt = 4))\n# [1] 80.96026 \n-10*log10(genotype_likelihood(m = 2, g= 1, e = 0.01, ref = 22, alt = 4))\n# [1] 78.2678\n-10*log10(genotype_likelihood(m = 2, g= 2, e = 0.01, ref = 22, alt = 4))\n# [1] 440.1746\n</code></pre> <p>Exercise: What is the most likely genotype? What is the genotype quality (GQ)? Do you think we should be confident about this genotype call?</p> Answer <p>The most likely genotype has the lowest PL, so where g=1 (heterozygous). GQ is calculated by subtracting the lowest PL from the second lowest PL, so 80.96 - 78.27 = 2.69. </p> <p>This is a low genotype quality (note that we\u2019re in the phred scale), i.e. an error probability of 0.54. This makes sense, if the genotype is heterozygous we would roughly expect to count as many reference as alternative alleles, and our example quite strongly deviates from this expectation. </p>"},{"location":"day2/variant_calling/#calling-variants-with-gatk","title":"Calling variants with GATK","text":"<p>The command <code>gatk HaplotypeCaller</code> is the core command of <code>gatk</code>. It performs the actual variant calling.</p> <p>Exercise: Check out the <code>gatk HaplotypeCaller</code> documentation, and find out which arguments are required.</p> Answer <p>Required arguments are:</p> <ul> <li><code>--input</code></li> <li><code>--ouput</code></li> <li><code>--reference</code></li> </ul> <p>Exercise: Generate a script called <code>B10_run_haplotype_caller.sh</code> in <code>B-mother_only</code>. Use it to make a directory called <code>~/project/results/variants</code> to write the output vcf. In the same script, run <code>gatk HaplotypeCaller</code> with required options on the recalibrated alignment file of the mother (<code>results/bqsr/mother.recal.bam</code>). We\u2019ll focus on a small region, so add <code>--intervals chr20:10018000-10220000</code>.</p> Answer B10_run_haplotype_caller.sh<pre><code>#!/usr/bin/env bash\n\ncd ~/project\nmkdir -p results/variants\n\ngatk HaplotypeCaller \\\n--reference data/reference/Homo_sapiens.GRCh38.dna.chromosome.20.fa \\\n--input results/bqsr/mother.recal.bam \\\n--output results/variants/mother.HC.vcf \\\n--intervals chr20:10018000-10220000\n</code></pre> <p>Exercise: You can get the number of records in a vcf with piping the output of <code>grep -v '^#'</code> to <code>wc -l</code>. Get the number of variants in the vcf.</p> Answer <pre><code>grep -v '^#' variants/mother.HC.vcf | wc -l\n</code></pre> <p>Shows you that there are 411 variants in there.</p> <p>You can get some more statistics with <code>gatk VariantsToTable</code>. The output can be used to easily query things in <code>R</code> or MS Excel.</p> <p>Here\u2019s an example:</p> <pre><code>gatk VariantsToTable \\\n--variant variants/mother.HC.vcf \\\n--fields CHROM -F POS -F TYPE -GF GT \\\n--output variants/mother.HC.table\n</code></pre> <p>Exercise: Run the command from within a script called <code>B11_variants_to_table.sh</code>, and have a look at the first few records (use e.g. <code>head</code> or <code>less</code>). After that, report the number of SNPs and INDELs.</p> Answer <p>Your script should look like:</p> B11_variants_to_table.sh<pre><code>cd ~/project\n\ngatk VariantsToTable \\\n--variant results/variants/mother.HC.vcf \\\n--fields CHROM -F POS -F TYPE -GF GT \\\n--output results/variants/mother.HC.table\n</code></pre> <p>You can get the number of SNPs with:</p> <pre><code>grep -c \"SNP\" variants/mother.HC.table\n</code></pre> <p>which will give 326</p> <p>And the number of INDELs with:</p> <pre><code>grep -c \"INDEL\" variants/mother.HC.table\n</code></pre> <p>that outputs 84</p> <p>A more fancy way to this would be:</p> <pre><code>cut -f 3 variants/mother.HC.table | tail -n +2 | sort | uniq -c\n</code></pre> <p>Giving:</p> <pre><code>84 INDEL\n1 MIXED\n326 SNP\n</code></pre> <p>Now, we will perform the variant calling on all three samples. Later we want to combine the variant calls. For efficient merging of vcfs, we will need to output the variants as a GVCF. To do that, we will use the option <code>--emit-ref-confidence GVCF</code>. Also, we\u2019ll visualise the haplotype phasing with IGV in the next section. For that we\u2019ll need a phased bam. You can get this output with the argument <code>--bam-output</code>.</p> <p>Exercise: Create a script in <code>C-all_samples</code> called <code>C06_run_haplotypecaller.sh</code>. Use it to run <code>gatk HaplotypeCaller</code> for mother, father and son in a loop. Use the same arguments as in the previous exercise. On top of that, add the arguments <code>--emit-ref-confidence GVCF</code> and <code>--bamoutput &lt;phased.bam&gt;</code>.</p> Answer C06_run_haplotypecaller.sh<pre><code>#!/usr/bin/env bash\n\ncd ~/project\n\nfor SAMPLE in mother father son\ndo\n    gatk HaplotypeCaller \\\n    --reference data/reference/Homo_sapiens.GRCh38.dna.chromosome.20.fa \\\n    --input results/bqsr/\"$SAMPLE\".recal.bam \\\n    --output results/variants/\"$SAMPLE\".HC.g.vcf \\\n    --bam-output results/variants/\"$SAMPLE\".phased.bam \\\n    --intervals chr20:10018000-10220000 \\\n    --emit-ref-confidence GVCF\ndone\n</code></pre>"},{"location":"day2/variant_calling/#2-combining-gvcfs","title":"2. Combining GVCFs","text":"<p>Now that we have all three GVCFs of the mother, father and son, we can combine them into a database. We do this because it enables us to later add GVCFs (with the option <code>--genomicsdb-update-workspace-path</code>), and to efficiently combine them into a single vcf.</p> <p>You can generate a GenomicsDB on our three samples like this:</p> C07_create_genomicsdb.sh<pre><code>#!/usr/bin/env bash\n\ncd ~/project\n\ngatk GenomicsDBImport \\\n--variant results/variants/mother.HC.g.vcf \\\n--variant results/variants/father.HC.g.vcf \\\n--variant results/variants/son.HC.g.vcf \\\n--intervals chr20:10018000-10220000 \\\n--genomicsdb-workspace-path results/genomicsdb\n</code></pre> <p>Exercise: Create a script called <code>C07_create_genomicsdb.sh</code> to run this command to generate the database.</p> <p>You can retrieve the combined vcf from the database with <code>gatk GenotypeGVCFs</code>.</p> C08_genotype_gvcfs.sh<pre><code>#!/usr/bin/env bash\n\ncd ~/project\n\ngatk GenotypeGVCFs \\\n--reference data/reference/Homo_sapiens.GRCh38.dna.chromosome.20.fa \\\n--variant gendb://results/genomicsdb \\\n--intervals chr20:10018000-10220000 \\\n--output results/variants/trio.vcf\n</code></pre> <p>Exercise: Create a script called <code>C08_genotype_gvcfs.sh</code> to run this command to generate the combined vcf.</p>"},{"location":"day2/variant_calling_preparation/","title":"Variant calling - preparation","text":""},{"location":"day2/variant_calling_preparation/#learning-outcomes","title":"Learning outcomes","text":"<p>After having completed this chapter you will be able to:</p> <ul> <li>Describe how variant information is stored in a variant call format (<code>.vcf</code>) file</li> <li>Describe the \u2018missing genotype problem\u2019 when calling variants of multiple samples, and the different methods on how this can be solved</li> <li>Applying Base Quality Score Recalibration on an alignment file</li> </ul>"},{"location":"day2/variant_calling_preparation/#material","title":"Material","text":"<p> Download the presentation</p> <p>VCF format description</p> <p>GATK best practices germline short variant workflow:</p>"},{"location":"day2/variant_calling_preparation/#exercises","title":"Exercises","text":""},{"location":"day2/variant_calling_preparation/#1-indexing-indexing-indexing","title":"1. Indexing, indexing, indexing","text":"<p>Many algorithms work faster, or only work with an index of their (large) input files. In that sense, <code>gatk</code> is no different from other tools. The index for a reference needs to be created in two steps:</p> <pre><code>cd ~/project/data/reference\nsamtools faidx &lt;reference.fa&gt;\ngatk CreateSequenceDictionary --REFERENCE &lt;reference.fa&gt;\n</code></pre> <p>Also input vcf files need to be indexed. This will create a <code>.idx</code> file associated with the <code>.vcf</code>. You can do this like this:</p> <pre><code>gatk IndexFeatureFile --input &lt;variants.vcf&gt;\n</code></pre> <p>Exercise: Create two scripts in <code>A-prepare_references</code> to generate the required indexes:</p> <ul> <li><code>A03_create_vcf_indices.sh</code>, in which you create indices for:<ul> <li>A part of the dbsnp database: <code>variants/GCF.38.filtered.renamed.vcf</code></li> <li>A part of the 1000 genomes indel golden standard: <code>variants/1000g_gold_standard.indels.filtered.vcf</code></li> </ul> </li> <li><code>A04_create_fasta_index.sh</code>, in which you create an index for:<ul> <li>The reference genome <code>reference/Homo_sapiens.GRCh38.dna.chromosome.20.fa</code></li> </ul> </li> </ul> <p>Note</p> <p>Indexes are often stored in the same directory as the indexed file. For the vcf and fasta indexes this is also the case. </p> Answer <p>Creating the indices for the vcfs:</p> A03_create_vcf_indices.sh<pre><code>#!/usr/bin/env bash\n\ncd ~/project/data \n\ngatk IndexFeatureFile --input variants/1000g_gold_standard.indels.filtered.vcf\ngatk IndexFeatureFile --input variants/GCF.38.filtered.renamed.vcf\n</code></pre> <p>Creating the index for the reference genome:</p> A04_create_fasta_index.sh<pre><code>#!/usr/bin/env bash\n\ncd ~/project/data \n\nsamtools faidx reference/Homo_sapiens.GRCh38.dna.chromosome.20.fa\ngatk CreateSequenceDictionary --REFERENCE reference/Homo_sapiens.GRCh38.dna.chromosome.20.fa\n</code></pre> <p>Chromosome names</p> <p>Unlike IGV, <code>gatk</code> requires equal chromosome names for all its input files and indexes, e.g. in <code>.fasta</code>, <code>.bam</code> and <code>.vcf</code> files. In general, for the human genome there are three types of chromosome names:</p> <ul> <li>Just a number, e.g. <code>20</code></li> <li>Prefixed by <code>chr</code>. e.g. <code>chr20</code></li> <li>Refseq name, e.g. <code>NC_000020.11</code></li> </ul> <p>Before you start the alignment, it\u2019s wise to check out what chromosome naming your input files are using, because changing chromosome names in a <code>.fasta</code> file is easier than in a <code>.bam</code> file.</p> <p>If your fasta titles are e.g. starting with a number you can add <code>chr</code> to it with <code>sed</code>:</p> <pre><code>sed 's/^&gt;/&gt;chr/g' &lt;reference.fasta&gt;\n</code></pre> <p>You can change chromsome names in a vcf with <code>bcftools annotate</code>:</p> <pre><code>bcftools annotate --rename-chrs &lt;tab-delimited-renaming&gt; &lt;input.vcf&gt;\n</code></pre>"},{"location":"day2/variant_calling_preparation/#2-base-quality-score-recalibration-bqsr","title":"2. Base Quality Score Recalibration (BQSR)","text":"<p>BQSR evaluates the base qualities on systematic error. It can ignore sites with known variants. BQSR helps to identify faulty base calls, and therefore reduces the chance on discovering false positive variant positions.</p> <p>BQSR is done in two steps:</p> <ol> <li>Recalibration with <code>gatk BaseRecalibrator</code></li> <li>By using the output of <code>gatk BaseRecalibrator</code>, the application to the bam file with <code>gatk ApplyBQSR</code></li> </ol> <p>Exercise: Check out the documentation of the tools. Which options are required?</p> Answer <p>For <code>gatk BaseRecalibrator</code>:</p> <ul> <li><code>--reference</code></li> <li><code>--input</code></li> <li><code>--known-sites</code></li> <li><code>--output</code></li> </ul> <p>For <code>gatk ApplyBQSR</code>:</p> <ul> <li><code>--bqsr-recal-file</code></li> <li><code>--input</code></li> <li><code>--output</code></li> </ul> <p>Exercise: Create a script in <code>B-mother_only</code> called <code>B09_perform_bqsr.sh</code> to execute the two bqsr commands. Do this with the required options on <code>mother.rg.md.bam</code>. At <code>--known-sites</code> specify <code>variants/1000g_gold_standard.indels.filtered.vcf</code> and <code>variants/GCF.38.filtered.renamed.vcf</code>.</p> <p>Multiple inputs for same argument</p> <p>In some cases you need to add multiple inputs (e.g. multiple <code>vcf</code> files) into the same argument (e.g. <code>--known-sites</code>). To provide multiple inputs for the same argument in <code>gatk</code>, you can use the same argument multiple times, e.g.:</p> <pre><code>gatk BaseRecalibrator \\\n--reference &lt;reference.fa&gt; \\\n--input &lt;alignment.bam&gt; \\\n--known-sites &lt;variants1.vcf&gt; \\\n--known-sites &lt;variants2.vcf&gt; \\\n--output &lt;output.table&gt;\n</code></pre> Answer B09_perform_bqsr.sh<pre><code>#!/usr/bin/env bash\n\ncd ~/project\n\nmkdir -p results/bqsr\n\ngatk BaseRecalibrator \\\n--reference data/reference/Homo_sapiens.GRCh38.dna.chromosome.20.fa \\\n--input results/alignments/mother.rg.md.bam \\\n--known-sites data/variants/GCF.38.filtered.renamed.vcf \\\n--known-sites data/variants/1000g_gold_standard.indels.filtered.vcf \\\n--output results/bqsr/mother.recal.table\n\ngatk ApplyBQSR \\\n--input results/alignments/mother.rg.md.bam \\\n--bqsr-recal-file results/bqsr/mother.recal.table \\\n--output results/bqsr/mother.recal.bam\n</code></pre> <p>Exercise: Place these commands in a \u2018for loop\u2019, that performs the BQSR for mother, father and son. Do this with a script called <code>C05_perform_bqsr.sh</code> in <code>C-all_samples</code>.</p> Answer C05_perform_bqsr.sh<pre><code>#!/usr/bin/env bash\n\ncd ~/project\n\nfor SAMPLE in mother father son\ndo\ngatk BaseRecalibrator \\\n--reference data/reference/Homo_sapiens.GRCh38.dna.chromosome.20.fa \\\n--input results/alignments/\"$SAMPLE\".rg.md.bam \\\n--known-sites data/variants/GCF.38.filtered.renamed.vcf \\\n--known-sites data/variants/1000g_gold_standard.indels.filtered.vcf \\\n--output results/bqsr/\"$SAMPLE\".recal.table\n\ngatk ApplyBQSR \\\n--input results/alignments/\"$SAMPLE\".rg.md.bam \\\n--bqsr-recal-file results/bqsr/\"$SAMPLE\".recal.table \\\n--output results/bqsr/\"$SAMPLE\".recal.bam\ndone\n</code></pre>"},{"location":"day2/visualisation/","title":"Visualisation","text":""},{"location":"day2/visualisation/#learning-outcomes","title":"Learning outcomes","text":"<p>After having completed this chapter you will be able to:</p> <p>Use IGV to:</p> <ul> <li>Visualise read alignments that support called variants</li> <li>Visualise phasing information generated by <code>gatk</code></li> </ul>"},{"location":"day2/visualisation/#material","title":"Material","text":"<p>IGV documentation</p>"},{"location":"day2/visualisation/#exercises","title":"Exercises","text":"<p>Download the following files to your local computer:</p> <ul> <li><code>variants/mother.phased.bam</code></li> <li><code>variants/mother.phased.bai</code></li> <li><code>bqsr/mother.recal.bam</code></li> <li><code>bqsr/mother.recal.bai</code></li> <li><code>variants/mother.HC.vcf</code></li> </ul> <p>Downloading files</p> <p>You can download files by right-click the file and after that select Download:</p> <p> </p> <p>Launch IGV and select the human genome version hg38 as a reference.</p> <p>Load the downloaded files as tracks in igv with File &gt; Load From File\u2026, and navigate to region <code>chr20:10,026,397-10,026,638</code>.</p> <p>Exercise: Zoom out for a bit. Not all reads are in the track of <code>mother.phased.bam</code>. What kind of reads are in there?</p> Answer <p>The reads supporting called variants.</p> <p>Now, we\u2019ll investigate the haplotype phasing.  Go back to <code>chr20:10,026,397-10,026,638</code>.</p> <p>Tip</p> <p>If your screen isn\u2019t huge, you can remove the track <code>mother.recal.bam</code>. Do that by right-click on the track, and click on Remove Track.</p> <p>In the track with <code>mother.phased.bam</code>, right click on the reads and select Group alignments by &gt; read group. This splits your track in two parts, one with artificial reads describing haplotypes that were taken in consideration (ArtificalHaplotypeRG), and one with original reads that support the variants.</p> <p>Exercise: How many haplotypes were taken into consideration? How many haplotypes can you expect at maximum within a single individual?</p> <p>Hint</p> <p>This might come as a shock, but humans are diploid.</p> Answer <p>Three haplotypes, as there are three artificial reads:</p> <p> </p> <p>Diploids can carry two haplotypes. So at least one of the three is wrong.</p> <p>Now colour the reads by phase. Do that with by right clicking on the track and choose Colour alignments by &gt; tag, and type in \u201cHC\u201d (that\u2019s the tag where the phasing is stored).</p> <p>Exercise: Which artificial read doesn\u2019t get support from the original sequence reads? Are the alternative alleles of the two SNPs on the same haplotype (i.e. in phase)?</p> Answer <p>The track should look like this (colours can be different):</p> <p> </p> <p>The reads only support the brown and blue haplotype, and not the pink one.</p> <p>The alternative alleles are coloured in IGV. For the first SNP this is the C (in blue) and for the second the T (in red). They are always in different reads, so they are in repulsion (not in phase).</p>"}]}